{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNlv9eTNY1oyk3S6MQ5Rz0I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elifsare/Titanic-Survival-Data/blob/main/Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABXxzpWb4OQD",
        "outputId": "6f22fcce-fd96-42ef-b91b-b2f14b7bf043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import re\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "from keras.engine import input_layer"
      ],
      "metadata": {
        "id": "3RmZxhCG5hsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(data):\n",
        "  data.Cabin.fillna('0', inplace=True)\n",
        "  data.loc[data.Cabin.str[0] == 'A', 'Cabin'] = 0\n",
        "  data.loc[data.Cabin.str[0] == 'B', 'Cabin'] = 1\n",
        "  data.loc[data.Cabin.str[0] == 'C', 'Cabin'] = 2\n",
        "  data.loc[data.Cabin.str[0] == 'D', 'Cabin'] = 3\n",
        "  data.loc[data.Cabin.str[0] == 'E', 'Cabin'] = 4\n",
        "  data.loc[data.Cabin.str[0] == 'F', 'Cabin'] = 5\n",
        "  data.loc[data.Cabin.str[0] == 'G', 'Cabin'] = 6\n",
        "  data.loc[data.Cabin.str[0] == 'T', 'Cabin'] = 7\n",
        "    \n",
        "  # Cinsiyeti tam sayıya çevirelim\n",
        "  data['Sex'].replace('female', 0, inplace=True)\n",
        "  data['Sex'].replace('male', 1, inplace=True)\n",
        "    \n",
        "  # Gemiye biniş limanlarını tam sayıya çevirelim\n",
        "  data['Embarked'].replace('S', 0, inplace=True)\n",
        "  data['Embarked'].replace('C', 1, inplace=True)\n",
        "  data['Embarked'].replace('Q', 2, inplace=True)\n",
        "    \n",
        "  # Olmayan (NA) yaş değerlerini medyan ile dolduralım\n",
        "  data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "  data['Fare'].fillna(data['Fare'].median(), inplace=True)\n",
        "  data['Embarked'].fillna(data['Embarked'].median(), inplace=True)\n",
        "    \n",
        "  # İstersek olmayan (NA) değerleri tamamen silebiliriz\n",
        "  # data.dropna(subset=['Fare', 'Embarked'], inplace=True, how='any')\n",
        "  return data\n",
        "\n"
      ],
      "metadata": {
        "id": "hpGxlJOe5hwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data içindeki gupların başlıklarıni değiştirme\n",
        "def group_titles(data):\n",
        "    data['Names'] = data['Name'].map(lambda x: len(re.split(' ', x)))\n",
        "    data['Title'] = data['Name'].map(lambda x: re.search(', (.+?) ', x).group(1))\n",
        "    data['Title'].replace('Master.', 0, inplace=True)\n",
        "    data['Title'].replace('Mr.', 1, inplace=True)\n",
        "    data['Title'].replace(['Ms.','Mlle.', 'Miss.'], 2, inplace=True)\n",
        "    data['Title'].replace(['Mme.', 'Mrs.'], 3, inplace=True)\n",
        "    data['Title'].replace(['Dona.', 'Lady.', 'the Countess.', 'Capt.', 'Col.', 'Don.', 'Dr.', 'Major.', 'Rev.', 'Sir.', 'Jonkheer.', 'the'], 4, inplace=True)"
      ],
      "metadata": {
        "id": "p2IQXZn25hzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_subset(data):\n",
        "    features = ['Pclass', 'SibSp', 'Parch', 'Sex', 'Names', 'Title', 'Age', 'Cabin'] #, 'Fare', 'Embarked']\n",
        "    lengh_features = len(features)\n",
        "    subset = data[features]#.fillna(0)\n",
        "    return subset, lengh_features\n"
      ],
      "metadata": {
        "id": "dRlOYyTX5h1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modelin içinde neler olacak, tasarım\n",
        "def create_model(train_set_size, input_lenght, num_epochs, batch_size):\n",
        "  # Define Sequential model with 3 layers\n",
        "  model = Sequential()\n",
        "  # Also, let's build a Sequential model incrementally via the add() method\n",
        "  model.Add(Dense(7, input_dim = input_lenght, activation='softplus')) # dense ----> katman\n",
        "  model.Add(Dense(3, activation='softplus'))\n",
        "  model.Add(Dense(1, activation='softplus'))\n",
        "\n",
        "  lr = .001 # Learning_rate, Defaults to 0.001.\n",
        "  adam0 = Adam(lr = lr)\n",
        "\n",
        "  # loss='binary_crossentropy'\n",
        "  # Entropy is a measure of the uncertainty associated with a given distribution q(y).\n",
        "  # Binary crossentropy is a loss function that is used in binary classification tasks. These are tasks that answer a question with only two choices. \n",
        "  #Several independent such questions can be answered at the same time, as in multi-label classification.\n",
        "  # Configures the model for training --> model.compile\n",
        "  model.compile(loss='binary_crossentropy', optimizer = adam0, metrics = ['accuracy'])\n",
        "  filepath = 'weights.best.hdf5' # öğrenilen ağırlığın kaydı için dosya\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor = 'acc', verbose = 1, save_best_only = True, mode = 'max') # checkpoint yardımıyla best result'ları belirler\n",
        "  callbacks_list = [checkpoint]\n",
        "  \n",
        "  history_model = model.fit(X_train[:train_set_size], Y_train[:train_set_size], callbacks=callbacks_list, epochs=num_epochs, batch_size=batch_size, verbose=0) #40, 32\n",
        "  return model, history_model"
      ],
      "metadata": {
        "id": "pL32-Zo55h4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(history):\n",
        "  loss_history = history.history['loss']\n",
        "  acc_history = history.history['acc']\n",
        "  epochs = [(i + 1) for i in range(num_epochs)]\n",
        "\n",
        "  ax = plt.subplot(211)\n",
        "  ax.plot(epochs, loss_history, color='red')\n",
        "  ax.set_xlabel('Epochs')\n",
        "  ax.set_ylabel('Error Rate\\n')\n",
        "  ax.set_title('Error Rate per Epoch\\n')\n",
        "\n",
        "  ax2 = plt.subplot(212)\n",
        "  ax2.plot(epochs, acc_history, color='blue')\n",
        "  ax2.set_xlabel('Epochs')\n",
        "  ax2.set_ylabel('Accuracy\\n')\n",
        "  ax2.set_title('Accuracy per Epoch\\n')\n",
        "  \n",
        "  plt.subplots_adjust(hspace=0.8)\n",
        "  plt.savefig('Accuracy_loss.png')\n",
        "  plt.close()\n",
        "                                   "
      ],
      "metadata": {
        "id": "xWUCJ_oL5h6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "el5McPEz5h9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZvqJu6Tp5iZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TYLMBm1l5ica"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T8AqIZbw5iew"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}